{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Multi-Panel Plot of 1-Degree Precipitation Datasets\n",
    "\n",
    "\n",
    "Use the Xarray module to read in daily 1-degree precip data from Brian Mapes' dataset archive at: \n",
    "http://weather.rsmas.miami.edu/repository/entry/show?entryid=synth%3Ad68cf65c-8cdd-4886-a61f-d03e877fea67%3AL2FnZ3JlZ2F0aW9ucy9kYWlseQ%3D%3D&ascending=true&orderby=name&showentryselectform=true\n",
    "\n",
    "The following code allows a user to specify the time and location of a case study, opens all of the datasets, and constructs a multi-panel plot with all of the results in one figure. In this updated version, only hard-wired parameters required are the manual changes to the case parameters at the top of this notebook. \n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell below is where you, the user, can specify a start and an end date, as well as the lat and lon bounds for a case of your choice. If you wish to select a case spanning multiple dates, the program will compute the precipitation sum for the length of the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date_start= '2006-06-28'\n",
    "date_end='2006-06-30'\n",
    "south=15 \n",
    "north=25\n",
    "west= 80        #of 360 deg\n",
    "east= 90      #of 360 deg "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the calls to load all of the datasets, create lists of the names and links,\n",
    "and convert them to a callable, iterable 2D array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all of our needed modules\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib as mpl\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "\n",
    "#Below are the calls to load all of the datasets, create lists of the names and links,\n",
    "#and convert them to a callable, iterable 2D array.\n",
    "\n",
    "gldas ='http://weather.rsmas.miami.edu/repository/opendap/synth:d68cf65c-8cdd-4886-a61f-d03e877fea67:L2FnZ3JlZ2F0aW9ucy9kYWlseS9wcmVjaXAuZ2xkYXMuZGFpbHlfYWdnLm5jbWw=/entry.das'\n",
    "cpcu = 'http://weather.rsmas.miami.edu/repository/opendap/synth:d68cf65c-8cdd-4886-a61f-d03e877fea67:L2FnZ3JlZ2F0aW9ucy9kYWlseS9wcmVjaXAuY3BjdS5kYWlseV9hZ2cubmNtbA==/entry.das'\n",
    "chirps = 'http://weather.rsmas.miami.edu/repository/opendap/synth:d68cf65c-8cdd-4886-a61f-d03e877fea67:L2FnZ3JlZ2F0aW9ucy9kYWlseS9wcmVjaXAuY2hpcnBzLmRhaWx5X2FnZy5uY21s/entry.das'\n",
    "trmm3b42 = 'http://weather.rsmas.miami.edu/repository/opendap/synth:d68cf65c-8cdd-4886-a61f-d03e877fea67:L2FnZ3JlZ2F0aW9ucy9kYWlseS9wcmVjaXAudHJtbTNiNDIuZGFpbHlfYWdnLm5jbWw=/entry.das'\n",
    "persiann = 'http://weather.rsmas.miami.edu/repository/opendap/synth:d68cf65c-8cdd-4886-a61f-d03e877fea67:L2FnZ3JlZ2F0aW9ucy9kYWlseS9wcmVjaXAucGVyc2lhbm4uZGFpbHlfYWdnLm5jbWw=/entry.das'\n",
    "mswep = 'http://weather.rsmas.miami.edu/repository/opendap/synth:d68cf65c-8cdd-4886-a61f-d03e877fea67:L2FnZ3JlZ2F0aW9ucy9kYWlseS9wcmVjaXAubXN3ZXAuZGFpbHlfYWdnLm5jbWw=/entry.das'\n",
    "merra = 'http://weather.rsmas.miami.edu/repository/opendap/synth:d68cf65c-8cdd-4886-a61f-d03e877fea67:L2FnZ3JlZ2F0aW9ucy9kYWlseS9wcmVjaXAubWVycmEuZGFpbHlfYWdnLm5jbWw=/entry.das'\n",
    "merrav2 = 'http://weather.rsmas.miami.edu/repository/opendap/synth:d68cf65c-8cdd-4886-a61f-d03e877fea67:L2FnZ3JlZ2F0aW9ucy9kYWlseS9wcmVjaXAubWVycmEyLmRhaWx5X2FnZy5uY21s/entry.das'\n",
    "jra55 = 'http://weather.rsmas.miami.edu/repository/opendap/synth:d68cf65c-8cdd-4886-a61f-d03e877fea67:L2FnZ3JlZ2F0aW9ucy9kYWlseS9wcmVjaXAuanJhNTUuZGFpbHlfYWdnLm5jbWw=/entry.das'\n",
    "gsmaprnl = 'http://weather.rsmas.miami.edu/repository/opendap/synth:d68cf65c-8cdd-4886-a61f-d03e877fea67:L2FnZ3JlZ2F0aW9ucy9kYWlseS9wcmVjaXAuZ3NtYXBybmwuZGFpbHlfYWdnLm5jbWw=/entry.das'\n",
    "gpcp1dd = 'http://weather.rsmas.miami.edu/repository/opendap/synth:d68cf65c-8cdd-4886-a61f-d03e877fea67:L2FnZ3JlZ2F0aW9ucy9kYWlseS9wcmVjaXAuZ3BjcDFkZC5kYWlseV9hZ2cubmNtbA==/entry.das'\n",
    "ecint = 'http://weather.rsmas.miami.edu/repository/opendap/synth:d68cf65c-8cdd-4886-a61f-d03e877fea67:L2FnZ3JlZ2F0aW9ucy9kYWlseS9wcmVjaXAuZWNpbnQuZGFpbHlfYWdnLm5jbWw=/entry.das'\n",
    "cmorph = 'http://weather.rsmas.miami.edu/repository/opendap/synth:d68cf65c-8cdd-4886-a61f-d03e877fea67:L2FnZ3JlZ2F0aW9ucy9kYWlseS9wcmVjaXAuY21vcnBoLmRhaWx5X2FnZy5uY21s/entry.das'\n",
    "cfsr = 'http://weather.rsmas.miami.edu/repository/opendap/synth:d68cf65c-8cdd-4886-a61f-d03e877fea67:L2FnZ3JlZ2F0aW9ucy9kYWlseS9wcmVjaXAuY2Zzci5kYWlseV9hZ2cubmNtbA==/entry.das'\n",
    "ens_mean = 'http://weather.rsmas.miami.edu/repository/opendap/synth:d68cf65c-8cdd-4886-a61f-d03e877fea67:L2FnZ3JlZ2F0aW9ucy9kYWlseS9wcmVjaXAuZW5zbWVhbi5kYWlseV9hZ2cubmNtbA==/entry.das'\n",
    "ens_rms = 'http://weather.rsmas.miami.edu/repository/opendap/synth:d68cf65c-8cdd-4886-a61f-d03e877fea67:L2FnZ3JlZ2F0aW9ucy9kYWlseS9wcmVjaXAuZW5zcm1zLmRhaWx5X2FnZy5uY21s/entry.das'\n",
    "\n",
    "#Group the names. \n",
    "dset_names= ['gldas', 'cpcu', 'chirps', 'trmm3b42', 'persiann', 'mswep', \n",
    "             'merra', 'merrav2', 'jra55', 'gsmaprnl', 'gpcp1dd', 'ecint',\n",
    "            'cmorph', 'cfsr', 'ens_mean', 'ens_rms']\n",
    "\n",
    "#and then group the links\n",
    "dsets=[gldas, cpcu, chirps, trmm3b42, persiann, mswep, merra, merrav2, \n",
    "       jra55, gsmaprnl, gpcp1dd, ecint, cmorph, cfsr, ens_mean, ens_rms]\n",
    "\n",
    "#Create array \"data_map\" from lists and stash names and links into columns\n",
    "data_map= []\n",
    "data_map= np.column_stack(tuple([dset_names, dsets]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, this is where the bulk of the code comes in. Using the parameters above, a 16-panel plot of various datasets and the ensemble mean & root-mean-square will be outputted. Any errors in the bounds will be displayed and must be addressed before the plot sequence can begin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plot error prechecks:\n",
    "#--------\n",
    "#Check for date mismatch by computing difference between date_start and date_end:\n",
    "from datetime import datetime\n",
    "def days_between(d1, d2):\n",
    "    d1 = datetime.strptime(d1, \"%Y-%m-%d\")\n",
    "    d2 = datetime.strptime(d2, \"%Y-%m-%d\")\n",
    "    return abs((d2 - d1).days)\n",
    "\n",
    "#Date check\n",
    "days_between(date_start, date_end)\n",
    "if date_start > date_end:\n",
    "    raise ValueError('Your end date is before your start date. Check your dates and try again.')\n",
    "\n",
    "#Longitudes\n",
    "if east < west:\n",
    "    raise ValueError('Your east longitude is less than your west longitude. Check your longitudes and try again.')\n",
    "\n",
    "#Latitudes\n",
    "if north < south:\n",
    "    raise ValueError('Your north latitude is less than your south latitude. Check your latitudes and try again.')\n",
    "\n",
    "#Check complete with no errors\n",
    "else:\n",
    "    print('Everything looks good. Starting plot sequence...')\n",
    "\n",
    "#--------START PLOT SEQUENCE---------#\n",
    "\n",
    "# Create the figure based on the MetPy Examples\n",
    "fig = plt.figure(figsize=(25, 25)) #Need a size large enough to avoid cramping of figure quality. \n",
    "gs = gridspec.GridSpec(5, 5, height_ratios=[1, 1, 1, 1, 0.05], width_ratios=[1,1,1,1,0.05], bottom=.05, top=.95, wspace=0.17, hspace=0.15)\n",
    "\n",
    "cols= 4 #Since we have 16 datasets, 4 columns will make plot evenly distributed.\n",
    "rows = int(len(data_map) / cols) # 16 datasets/ 4 datasets/columns= 4 rows\n",
    "\n",
    "#Define the plot background here. It speeds up the plotting process to not embed it in the forthcoming loop.\n",
    "def plot_background(ax):\n",
    "    ax.set_extent([datalon.min(), datalon.max(), datalat.min(), datalat.max()]) #Extent based on lat-lon slice above.\n",
    "    ax.coastlines('50m', edgecolor='black', linewidth=0.5)\n",
    "    #ax.add_feature(states_provinces, edgecolor='gray')\n",
    "    \n",
    "    #Now for the lat-lon\n",
    "    ax.set_xticks(np.linspace(datalon.min(), datalon.max(), num= 3, endpoint= True), crs=ccrs.PlateCarree())\n",
    "    ax.set_yticks(np.linspace(datalat.min(), datalat.max(), num= 3, endpoint= True), crs=ccrs.PlateCarree())\n",
    "    lon_formatter = LongitudeFormatter(zero_direction_label=True)\n",
    "    lat_formatter = LatitudeFormatter()\n",
    "    ax.xaxis.set_major_formatter(lon_formatter)\n",
    "    ax.yaxis.set_major_formatter(lat_formatter)\n",
    "    return ax\n",
    "\n",
    "#Retrieve the data from the data sources in the csv file and perform calculations.\n",
    "\n",
    "for i in range(cols):\n",
    "    for j in range(rows):\n",
    "        \n",
    "        idx = (cols*i)+j #Obtain each individual data URL as index.\n",
    "        dnum= data_map[idx][0] #Retrieve datanumber\n",
    "        \n",
    "        data = xr.open_dataset(data_map[idx][1], decode_times=True)\n",
    "        datatitle= data.product_id\n",
    "        \n",
    "        datalat= data.lat[(south)+90:(north)+90] #Because the latitude units are strictly in degrees north, we must add 90 to account for southern hemisphere. \n",
    "                                                 #Otherwise, we will end up with index values which would yield incorrect latitudes.\n",
    "        datalon= data.lon[west:east]\n",
    "        event = data.precip.sel(time=slice(date_start, date_end),lat=slice(datalat.min(), datalat.max()),lon=slice(datalon.min(), datalon.max()))\n",
    "        pcp = np.sum(event, axis=0)*86400\n",
    "        \n",
    "        #List \n",
    "        \n",
    "        #Define cartopy grid:\n",
    "        crs = ccrs.PlateCarree(central_longitude=((datalon.max()+datalon.min())/2))\n",
    "\n",
    "        #Assign the 2D lon and lat variables to construct plot.\n",
    "\n",
    "        lon_2d= np.linspace((datalon.min()), (datalon.max()), num= ((datalon.max()- datalon.min())+1), endpoint= True)\n",
    "        lat_2d= np.linspace((datalat.min()), (datalat.max()), num= ((datalat.max()- datalat.min())+1), endpoint= True)\n",
    "\n",
    "        #Now for the evenly-spaced contours, separated into 4 categories of precip accumulation:\n",
    "        if pcp.max() <= 300:\n",
    "            levels= np.arange(0,pcp.max(),30)\n",
    "        elif 300 < pcp.max() <= 600:\n",
    "            levels= np.arange(0,pcp.max(),60)\n",
    "        elif 600 < pcp.max() <= 900:\n",
    "            levels= np.arange(0,pcp.max(),90)\n",
    "        elif pcp.max() > 900:\n",
    "            levels= np.arange(0,pcp.max(),100)\n",
    "        \n",
    "        # plot the data accordingly\n",
    "        ax1 = plt.subplot(gs[i, j], projection=crs)\n",
    "        plot_background(ax1)\n",
    "        \n",
    "        cf1= ax1.pcolormesh(lon_2d, lat_2d, pcp, cmap='Greens', transform=ccrs.PlateCarree())\n",
    "        \n",
    "        if idx == 15: #Ensemble RMS plot\n",
    "            cf2= ax1.pcolormesh(lon_2d,lat_2d, pcp, cmap='Blues', transform=ccrs.PlateCarree())\n",
    "        \n",
    "        c1 = ax1.contour(lon_2d, lat_2d, pcp, colors='red', linewidths=2, levels=levels)\n",
    "        \n",
    "        plt.clabel(c1, fontsize=15, inline=1, inline_spacing=1, fmt='%i', rightside_up=True)\n",
    "        \n",
    "        ax1.set_title('({}) {} '.format(chr(97+idx), datatitle), fontsize=22)\n",
    "        \n",
    "        # plot the color scale\n",
    "        bounds_pcp= np.linspace(0,np.around(pcp.max(), decimals=-1), num= 11) # pcp.max will adjust based on case study extrema, but one can modify the color spacing value to higher/lower amounts as needed.\n",
    "        \n",
    "        norm = mpl.colors.BoundaryNorm(boundaries=bounds_pcp, ncolors=256)\n",
    "        \n",
    "        side_bar_ax = plt.subplot(gs[4, :-1])\n",
    "        cb = mpl.colorbar.ColorbarBase(side_bar_ax, cmap='Greens',\n",
    "                        norm=norm,\n",
    "                        extend='both',\n",
    "                        extendfrac='auto',\n",
    "                        ticks=bounds_pcp,\n",
    "                        spacing='uniform',\n",
    "                        orientation='horizontal')\n",
    "        if idx == 15:\n",
    "            side_bar_ax = plt.subplot(gs[3, 4])\n",
    "            cb = mpl.colorbar.ColorbarBase(side_bar_ax, cmap='Blues',norm=norm, extend='both',\n",
    "                        extendfrac='auto', ticks=bounds_pcp, spacing='uniform', orientation='vertical')\n",
    "\n",
    "        font_size_cb = 18 # Adjust as appropriate.\n",
    "        cb.ax.tick_params(labelsize=font_size_cb)\n",
    "        cb.set_label('Precipitation (mm/day)', fontsize=22)\n",
    "        \n",
    "        #Now focus on the ensemble RMS to change its color scheme and add specific colorbar.\n",
    "\n",
    "if date_start == date_end:   \n",
    "    fig.suptitle('rainfall accumulation for case on: ' + date_start, fontsize=28)\n",
    "elif date_start != date_end:\n",
    "    fig.suptitle('rainfall accumulation for case from: ' + date_start + ' to ' +date_end, fontsize=28)\n",
    "    \n",
    "#Plot saves to same directory as this notebook by default. User can change this to match specific needs.\n",
    "plt.savefig('Precipitation_multiplot_' + date_start + '.png', bbox_inches='tight')\n",
    "\n",
    "print('SUCCESS! Your plot is complete...')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cells underneath can be created so if one would like to write up a quick summary on a case, it is readily available to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
